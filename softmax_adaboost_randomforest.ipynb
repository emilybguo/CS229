{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilybguo/CS229/blob/main/softmax_adaboost_randomforest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook holds code for data preprocessing and 3 out of our 4 overall ML algorithms: softmax regression, AdaBoost, and Random Forest."
      ],
      "metadata": {
        "id": "1Wx79UaCLQqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import relevant libraries"
      ],
      "metadata": {
        "id": "vXyKZur5FoRS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvkA7T0_yuWe"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import sklearn \n",
        "\n",
        "# For standardizing dataset\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# library for multiclass model metrics\n",
        "!pip install disarray\n",
        "import disarray\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        " # For splitting of data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "# For metrics and confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "\n",
        "# Scikit-learn ML models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKod3tZVsgmq"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJI01dcNsAHT"
      },
      "source": [
        "In this file, we preprocess the data to prepare it for testing on machine learning algorithms. This includes controlling for variables, removing those we do not want to consider, and splitting catagorical data into one-hot vectors that allow us to include them in algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeXVryw4x2uO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWspmRvQybwI"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/CS229 project/cleaned_data_12_09.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create train, validation, and test sets."
      ],
      "metadata": {
        "id": "wUrsxP-2Fe5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TAuqYURru54"
      },
      "outputs": [],
      "source": [
        "x = df.drop(columns = ['action_taken']).copy()\n",
        "y = df['action_taken']\n",
        "\n",
        "# first, split data into training and remaining datasets, with training as 80% of \n",
        "# original dataset size\n",
        "x_train, x_rem, y_train, y_rem = train_test_split(x, y, train_size=0.8, shuffle = True, random_state=0)\n",
        "\n",
        "# next, split remaining data into validation and test datasets, with both as 10%\n",
        "# of the original dataset size (50% of the remaining 20%)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_rem, y_rem, test_size=0.5, shuffle = True, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print frequency of each class in each dataset."
      ],
      "metadata": {
        "id": "MJoSbGp0FRm9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDBebEZrG7sw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63d71a1-65b0-429f-db4b-794daa8c1a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The list frequency of elements in y_train is : {3: 16869, 6: 3866, 2: 3776}\n",
            "The list frequency of elements in y_valid is : {3: 2118, 2: 487, 6: 459}\n",
            "The list frequency of elements in y_valid is : {2: 459, 3: 2069, 6: 536}\n"
          ]
        }
      ],
      "source": [
        "d = {}\n",
        "\n",
        "for x in y_train:\n",
        "    d[x] = d.get(x,0) + 1\n",
        "\n",
        "# printing result\n",
        "print(f\"The list frequency of elements in y_train is : {d}\" )\n",
        "\n",
        "e = {}\n",
        "\n",
        "for x in y_valid:\n",
        "    e[x] = e.get(x,0) + 1\n",
        "\n",
        "# printing result\n",
        "print(f\"The list frequency of elements in y_valid is : {e}\" )\n",
        "\n",
        "f = {}\n",
        "\n",
        "for x in y_test:\n",
        "    f[x] = f.get(x,0) + 1\n",
        "\n",
        "# printing result\n",
        "print(f\"The list frequency of elements in y_valid is : {f}\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run to save all datasets to Drive."
      ],
      "metadata": {
        "id": "rTXQ4oMkFtkV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm9SnRye-ZrC"
      },
      "outputs": [],
      "source": [
        "# save x_train\n",
        "with open('/content/gdrive/MyDrive/CS229 project/x_train.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  x_train.to_csv(f)\n",
        "\n",
        "# save x_valid\n",
        "with open('/content/gdrive/MyDrive/CS229 project/x_valid.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  x_valid.to_csv(f)\n",
        "\n",
        "# save x_test\n",
        "with open('/content/gdrive/MyDrive/CS229 project/x_test.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  x_test.to_csv(f)\n",
        "\n",
        "# save y_train\n",
        "with open('/content/gdrive/MyDrive/CS229 project/y_train.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  y_train.to_csv(f)\n",
        "\n",
        "# save y_valid\n",
        "with open('/content/gdrive/MyDrive/CS229 project/y_valid.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  y_valid.to_csv(f)\n",
        "\n",
        "# save y_test\n",
        "with open('/content/gdrive/MyDrive/CS229 project/y_test.csv', 'w', encoding = 'utf-8-sig') as f:\n",
        "  y_test.to_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize datasets based on x_train."
      ],
      "metadata": {
        "id": "abh1VMkNFz2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "\n",
        "x_train = scaler.transform(x_train)\n",
        "x_valid = scaler.transform(x_valid)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "NlKYOfb5EutN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3DL_O1v6oOW"
      },
      "source": [
        "# Machine learning algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0D4hl7rBQOo"
      },
      "source": [
        "### Model 1: Softmax "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_baseline = LogisticRegression(max_iter=1000, penalty = 'none').fit(x_train, y_train) \n",
        "softmax_baseline.score(x_valid, y_valid)\n"
      ],
      "metadata": {
        "id": "DIJT4y6aPrtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame(df.columns.values[:-1].tolist(), columns = [\"feature\"])\n",
        "feature_importance[\"importance\"] = np.power(np.e, softmax_baseline.coef_[0])\n",
        "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=False)\n",
        "\n",
        "feature_importance[:10]"
      ],
      "metadata": {
        "id": "C9EceY6yGLSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ1a8UuRMyda"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_valid, softmax_baseline.predict(x_valid), labels= softmax_baseline.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=softmax_baseline.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.accuracy, metrics.da.precision, metrics.da.recall"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: AdaBoost"
      ],
      "metadata": {
        "id": "Scz2ctDCX-n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada = AdaBoostClassifier(learning_rate = 0.1, n_estimators=10, base_estimator=DecisionTreeClassifier(max_depth=6, min_samples_leaf= 5)).fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "i4-39C3FjCdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ada.score(x_valid, y_valid)"
      ],
      "metadata": {
        "id": "Rvx__xq_blzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_valid, ada.predict(x_valid), labels= ada.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=ada.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.accuracy, metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "z8--ghxFbnJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp = pd.Series(ada.feature_importances_, index = df.columns.values[:-1]).sort_values(ascending = False)\n",
        "feature_imp[:10]"
      ],
      "metadata": {
        "id": "V-tMejJCAy0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "o2CaRhl5lPtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unbalanced\n",
        "rf = RandomForestClassifier(n_estimators= 1800, max_depth = 30, \n",
        "                            min_samples_split = 10, \n",
        "                            min_samples_leaf = 1, max_features = 'sqrt',\n",
        "                            bootstrap = False).fit(x_train, y_train)\n",
        "rf.score(x_valid, y_valid)\n",
        "\n"
      ],
      "metadata": {
        "id": "qTDVqcm7lTVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# balanced\n",
        "rf_b = RandomForestClassifier(n_estimators= 1800, max_depth = 30, \n",
        "                            min_samples_split = 10, \n",
        "                            min_samples_leaf = 1, max_features = 'sqrt',\n",
        "                            bootstrap = True, class_weight= 'balanced_subsample').fit(x_train, y_train)\n",
        "rf_b.score(x_valid, y_valid)\n",
        "\n"
      ],
      "metadata": {
        "id": "KgfpbrH_rXbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_valid, rf.predict(x_valid), labels= rf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=rf.classes_)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.accuracy, metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "KmQszQUlc4zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp = pd.Series(rf.feature_importances_, index = df.columns.values[:-1]).sort_values(ascending = False)\n",
        "feature_imp[:10]"
      ],
      "metadata": {
        "id": "--6tt-UaBX6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Models"
      ],
      "metadata": {
        "id": "w4mqXu0ebz3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline: \", softmax_baseline.score(x_test, y_test))\n",
        "print(\"AdaBoost: \", ada.score(x_test, y_test))\n",
        "print(\"RF (unbalanced): \", rf.score(x_test, y_test))\n",
        "print(\"RF (balanced): \", rf_b.score(x_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "L3wZkpbab5bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline"
      ],
      "metadata": {
        "id": "UcDYRW0LHM5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, softmax_baseline.predict(x_test), labels= softmax_baseline.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=softmax_baseline.classes_)\n",
        "disp.plot()\n",
        "plt.title(\"Baseline Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "1rfTTQLFcXck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost"
      ],
      "metadata": {
        "id": "8LFU80klHYqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, ada.predict(x_test), labels= ada.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=ada.classes_)\n",
        "disp.plot()\n",
        "plt.title(\"AdaBoost Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "9Q9avJUgHWhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (Unbalanced)"
      ],
      "metadata": {
        "id": "bA8WBgVArKLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, rf.predict(x_test), labels= rf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=rf.classes_)\n",
        "disp.plot()\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "eoqiEJoYrNdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (Balanced)"
      ],
      "metadata": {
        "id": "7vK56ETeHboj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, rf_b.predict(x_test), labels= rf_b.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=rf_b.classes_)\n",
        "disp.plot()\n",
        "plt.title(\"Random Forest (Balanced) Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "metrics = pd.DataFrame(cm, dtype=int)\n",
        "metrics.da.precision, metrics.da.recall"
      ],
      "metadata": {
        "id": "Jg2i0zQuHdms"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}